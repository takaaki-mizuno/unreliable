---
title: "ソフトウエア技術書翻訳とAI"
emoji: "📗"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["AI", "翻訳"]
published: false
---

:::message
この記事は、ソフトウエアに関する技術書の翻訳と、それにどうAIを活用するかについて、自分の経験をもとに解説したものです。
:::

## はじめに

私は、翻訳や語学の専門家ではありませんが、ソフトウエアの技術書の翻訳を仕事の一部としており、これまで10冊の翻訳をしています。本記事では、これまでの翻訳の経験をもとに、ソフトウエア技術書の翻訳と、それにどうAIを活用するかについて解説します。

これまで私が翻訳した書籍は以下のとおりです。

- [JavaScript: The Good Parts ( 2008 )](https://www.amazon.co.jp/dp/4873113911/)
- [ウェブアプリケーションのためのユニバーサルデザイン( 2009 )](https://www.amazon.co.jp/dp/4873114322/)
- [入門 自然言語処理 ( 2010 )](https://www.amazon.co.jp/dp/4873114705/)
- [ハイパフォーマンスJavaScript ( 2011 )](https://www.amazon.co.jp/dp/487311490X/)
- [入門 機械学習 ( 2012 )](https://www.amazon.co.jp/dp/4873115949/)
- [オブジェクト指向JavaScript ( 2012 )](https://www.amazon.co.jp/dp/4048706705/)
- [サードパーティJavaScript ( 2014 )](https://www.amazon.co.jp/dp/4798072796/)
- [プログラマー脳 ( 2023 )](https://www.amazon.co.jp/dp/4798068535/)
- [ストレンジコード ( 2024 )](https://www.amazon.co.jp/dp/4798069744/)
- [システム設計面接の傾向と対策 ( 2025 )](https://www.amazon.co.jp/dp/4798072796/)

これらの書籍の翻訳には、AIや機械翻訳を使っていますが、使っているルールは、時代とともに変化しています。今回は、その変遷などを追っていきたいと思います。

## 翻訳を始めたきっかけ

自分が初めて翻訳した書籍は、オライリーの [JavaScript: The Good Parts ( 2008 )](https://www.amazon.co.jp/dp/4873113911/) です。この本は、JSONの「発見者」であることで知られるダグラス・クロフォード氏が書いた名著であり、「The Good Parts」のシリーズを生み出した書籍でもあります。ちなみに自分も「[Web API: The Good Parts (2014)](https://www.amazon.co.jp/dp/4873116864/)という本を書いています。なお、この本はよく翻訳と勘違いされますが、自分が書き下ろした本で、英語版はありません（中国語には翻訳されました）。

[JavaScript: The Good Parts](https://www.amazon.co.jp/dp/4873113911/) を翻訳することになったきっかけは、2008年5月に東工大（当時）の大岡山キャンパスで行われた[YAPC::Asia 2008](http://conferences.yapcasia.org/ya2008/)での出来事でした。ちょうど休憩時間に、知り合いだった当時オライリージャパンにいらっしゃった編集者の方と雑談をしていたのですが、その時に「水野さんは翻訳とか興味ないんですか」と聞かれたのです。「興味あります」と答えたところ「じゃあ、翻訳したい本あったら教えてください」と言われました。

あれ、「この本を翻訳してもらえませんか」みたいな流れじゃないんだなと、その時思った覚えがありますが、翻訳にはとても興味があったので、その日の晩に早速オライリーメディアのウェブサイトを開いて、何かいい本はないものかと探し始めました。そこで見つけたのがJavaScript: The Good Parts でした。ただし当時は、大変失礼なことに、この本が名著なことも、書いたのが超有名人であることも、全然知りませんでした。ただ、200ページくらいの薄めの本で、翻訳しやすそうだし、JavaScriptの本なら知識もあるし大丈夫だろう、くらいの気持ちで「この本やってみたいです」と編集の方にメールを打ちました。

すると「この本はまだ翻訳権が空いているので、この本にしましょう」というお返事をもらうことができて、翻訳をスタートすることができたのです。

当たり前ですが、書籍の翻訳では、「この本翻訳させてください」という契約が一旦まとまると、他の人は翻訳できなくなります。どんなに翻訳したくても、先に抑えられたら翻訳できないので、こんな良い本がたまたま空いていたのは、今思えば非常にラッキーなことです。

そして、原著のPDFを受け取り、翻訳作業が始まり、年内に出版することができました。結局、翻訳には4ヶ月くらいかかった気がします。当時中国の検索エンジンサービス会社である百度に勤めていて、中国出張が月1回くらいで入っていたので、空港や飛行機の中で翻訳をやったのをよく覚えています。

幸いにも「JavaScript: The Good Parts」は好評で、よく売れました。当時、技術者界隈で非常に頻繁に発言をしていた[小飼弾さん](https://www.dan.co.jp/%7Edankogai/)が、ブログでたびたび紹介してくれ（JavaScriptのネタのたびにリンクを貼ってくれた）、その度に重版がかかったので、Dan Kogai特需と呼んでいました。弾さん本当にありがとうございます。

そのおかげもあって、その後もオライリーを中心に、何冊も技術書の翻訳の機会をもらえまして、2014年くらいまで、結構な頻度で訳書を出すことができました。

その後、しばらく間が空いてしまいましたが、以前から知り合いの編集者の西田さんという方が、秀和システムに転職されて、翻訳書をやることになって声をかけてもらえたのをきっかけに、毎年1冊くらいのペースで翻訳を行なっています。なお、西田さんは2024年の[ITエンジニア本大賞](https://www.shoeisha.co.jp/campaign/award/2024/result)に彼自身が編集した（秀和システムが、ではない）書籍が3冊も入るという化け物みたいな人であり、声をかけてもらえて本当にありがたい話です。

## 書籍の翻訳と機械翻訳サービス

自分が翻訳を始めた2008年には、もちろん今のような生成AIのサービスがありませんでしたが、機械翻訳サービスはありました。当時は、2022年にサービスを終了してしまったExcite 翻訳が有名でして、JavaScript: The Good Partsでも、大変お世話になりました。

翻訳の作業は、まずは受け取ったPDFを、テキストデータに変換するところから始まります。今は、PDFを扱うライブラリも多く、自分も仕事でPDFからのデータ抽出を数多くやったため、ある程度自動化できますし、生成AIにファイルを投げてテキスト化することもできますが、当時はあまりいい方法が思いつかず、手作業でコピー&ペーストを繰り返した覚えがあります。

そして翻訳は、段落ごとに英語の原文の下に翻訳した日本語を書いていき、わからないところなどは適宜Excite 翻訳に投げる、ということをしていきました。

当時の機械翻訳の品質はまだまだで、意味はわからないでもないものの、そのまま訳文として利用するには程遠い、と言ったものだったので、文意をある程度把握することにしか使えず、

Google翻訳も当時からありましたが、日英の翻訳はまだ登場当時はかなり下手くそでした。

その後、Google翻訳の精度は徐々に上がっていきましたが、Google翻訳で翻訳した文章をそのまま使う、というのはまだ難しく、相当な書き換えが必要だったと記憶しています。

その当時、これらの機械翻訳のツールを使う問題点はいくつもありましたが、翻訳そのものの品質以外に、たとえば以下のようなものがありました。

- 段落単位での翻訳のため、翻訳に文脈が考慮されない
- 専門用語の翻訳がうまくいかない

これはもちろん、人間が翻訳した場合にも起こりうる問題ですし、[翻訳メモリ](https://ja.wikipedia.org/wiki/%E7%BF%BB%E8%A8%B3%E3%83%A1%E3%83%A2%E3%83%AA)を使うなど、ある程度解決する方法があるのですが、特に翻訳について体系的に学んだわけでもなく、翻訳についてはズブの素人であった私は、そういう知識もなく、試行錯誤と力技で翻訳を行なっていました。

専門用語の翻訳がうまくいかない点については、あらかじめそう言った語を英語の原文中で日本語に翻訳しておく（たとえば英語中の「feature engineering」を「特徴量エンジニアリング」に置換しておく）、といったことをしていたのを覚えています。そうすると、英語の中に日本語が混ざった変な状態になりますが、機械翻訳にかけると、もともと日本語の部分はそのまま日本語になるので、語の統一が図られるという寸法です。

## 生成AIと翻訳その1 ( GPT 4.0 と DeepL )

私は、2014年にサードパーティJavaScriptを翻訳した後、忙しかったこともあり8年くらい書籍の翻訳（執筆も）をやらない期間がありました。そして久しぶりに翻訳のお話をいただいて「プログラマー脳」の翻訳を始めたときに、これまでと大きく違ったことは、[DeepL](https://www.deepl.com/ja/translator)が存在していたことです。

DeepLは2017年に登場しており、登場した際には、その高い精度に、世の中に衝撃を与えました。ちょうどその頃、[Google翻訳](https://translate.google.co.jp/)もニューラルネットワークに移行しており、この頃に機械翻訳は大きく精度が向上したようです。

「プログラマー脳」の翻訳作業は2022年の夏から冬にかけて行いましたが、この際にはDeepLを使って、わからない部分の翻訳を行なっていました。しかし、この段階ではまだ、機械翻訳はあくまでサポートに過ぎず、翻訳の大部分は手動で行なっていました。

生成AIを使った翻訳を試したのは、2023年に「ストレンジコード」を翻訳した時からです。ChatGPTが登場したのは2022年の11月であり、「ストレンジコード」の翻訳を開始した2023年の5月には、GPT 4.0のAPIを利用することができたからです。

そこで「ストレンジコード」では、GPT 4.0のAPIとDeepLのAPIを併用して、翻訳を行なってみました。「ストレンジコード」の原文データはTeXで書かれていたので、それをまずMarkdownに変換し、段落ごとにGPT 4.0のAPIとDeepLのAPIの両方に投げ、結果を英語、DeepLの結果、GPT 4.0 の結果、というように並べて、1章ごとにファイルを分けて保存しました。そして、その3つを比較しながら、最終的な訳文を書いていきました。なお、コードブロックなどは、翻訳対象からはずし、そのままMarkdownのコードブロックとして保存するようにして、無駄にAPIに投げないようにしてありました。

以下にストレンジコードの第1章から、原文、DeepLの結果、GPT 4.0の結果、そして最終的な訳文の例を示します。

### 原文

> Listing 1-5 shows us how to define and use classes. We define two classes, Person and Pal, a subclass of Person. Person uses the familiar class keyword and then defines first and last names as type text, a string object, along with age, an integer. Person defines one method, Print, to print the person’s full name and age.

### DeepLの結果

> リスト 1-5 は、クラスの定義と使い方を示している。 ここでは2つのクラス、PersonとPersonのサブクラスであるPalを定義します。 Person はおなじみの class キーワードを使用し、姓と名を text 型の文字列オブジェクトとして定義し、age は整数値として定義しています。 Person は人のフルネームと年齢を表示するために Print というメソッドを1つ定義しています。

### GPT 4.0の結果

> リスト 1-5は、クラスの定義と使い方を示しています。ここでは、Personというクラスと、そのサブクラスであるPalというクラスを2つ定義しています。Personは、おなじみのclassキーワードを使用して、姓と名を文字列オブジェクトのtext型として定義し、年齢を整数として定義しています。PersonはPrintというメソッドを1つ定義し、その人のフルネームと年齢を表示します。

### これらの結果をもとにした最終的な訳文

> リスト 1-5は、クラスの定義と使い方を示しています。ここでは、Personというクラスと、そのサブクラスであるPalという2つのクラスを定義しています。Personは、おなじみのclassキーワードを使用して、姓と名をtext型（文字列オブジェクト）として定義し、年齢を整数として定義しています。PersonにはPrintというメソッドが定義されており、これはその人のフルネームと年齢を表示する機能を持ちます。

DeepLの結果は、ですます調とである調が混ざってしまっています。GPT 4.0の結果は、DeepLの結果よりも、読みやすく自然な文章になっているのがわかります。個人的に内容を理解するためには十分なのですが、読んだ時のリズムは、個人的には今ひとつな場合もあるなと感じました。そのまま最終的な訳文として使える場合もありましたが、多くの場合は、より読みやすい（と私自身が考える）文章に書き換えていきました。例えば「クラスを2つ定義しています」を「2つのクラスを定義しています」に変えたあたりなどが、リズムを意識した部分です。

ちなみに、DeepLは段落をまとめて翻訳させると、1文がまるまる抜けて翻訳されることがあったので、文ごとに分割して翻訳し、結果を段落としてまとめるコードを書くようにしました。GPT 4.0には、「ですます調で訳すこと」や「なるべく自然な文章、かつあまり意訳をせずに原文の意味をそのまま残すこと」などを指示しています。

ここで得られた大きな知見は、複数のツールで行った翻訳結果を比較して、最終的な結果とするのはなかなか良い、ということです。一つの翻訳だけだと文意が取りづらい場合でも、複数の結果を比較することで、意味が理解できる場合があるからです。「ストレンジコード」は原著で500ページ、翻訳では600ページを超える書籍だったので、全てを翻訳するのは大変で、この方法で翻訳したからこそ、数ヶ月という期間で翻訳することができたのだと思います。

## 生成AIと翻訳その2 ( Claude 3.5 )

「[システム設計面接の傾向と対策](https://www.amazon.co.jp/dp/4798072796/)」の翻訳は、2024年の6月から10月にかけて行いました。翻訳を開始する直前、Claude 3.5 がリリースされました。Claude 3.5は200Kトークンというめちゃくちゃでっかいコンテキストウィンドウを備えていたので、一章分のデータを丸ごと渡して、翻訳をすることができるようになりました。

翻訳にあたっては、今回はPDFやTeXではなく、HTMLファイルをもとにしています。「システム設計面接の傾向と対策」の原著は[Manning社](https://www.manning.com/books/acing-the-system-design-interview)から出版されており、Manning社のサイトでは、オンライン版の購入をすると、書籍をブラウザ上で読むことができます。このオンライン版はHTMLで作られているので、それをデベロッパーツールでコピーして、HTMLデータとして章ごとに取得しました。

HTMLファイルは、見出しなどの情報がタグによって構造化されているので、このファイルをそのままClaude 3.5に渡して、章ごとに翻訳を行いました。APIではなく、Web版のClaudeを利用しました。出力結果は、一度には出ないのですが、「続ける」などのメッセージで先を促し、一章ごとの翻訳ファイルをMarkdownファイルとして作成することができました。

ではここで、「システム設計面接の傾向と対策」の2.2節の冒頭の原文と、Claude 3.5の結果、最終的な訳文を示します。

### 原文

> You should have already clarified the functional requirements before scribbling these endpoints; you are past the appropriate section of the interview to clarify functional requirements and should not do so here unless you missed anything.

### Claude 3.5の結果

> エンドポイントをメモする前に、既に機能要件を明確にしているはずです。面接の適切なセクションを過ぎてから機能要件を明確にするのは適切ではありません。重要なことを見逃した場合を除いて、ここで機能要件を明確にすべきではありません。

### これらの結果をもとにした最終的な訳文

> エンドポイントの草案を作る前に、あなたは機能要件を明確にしているはずです。面接においては後になってから機能要件の明確化を行うのは適切ではありません。重要なことを見逃した場合を除いて、今の段階になってから機能要件の詳細を議論すべきではありません。

Claude 3.5の結果は、すでに、かなり自然な文章になっているのがわかります。しかも、1章分をまるごとを渡して翻訳させることができるので、かなり文脈も理解した上での翻訳ができていることがわかります。単に内容を理解しようとするだけなら、十分だとも言えるでしょう。

ただし、文章がやや堅苦しく、「面接の適切なセクションを過ぎてから...」など、直訳すぎる気もします。そこで、主語を追加したり、リズムを考えて読みやすくするよう、文章を修正しています。

また、専門用語の翻訳など、用語の統一も行なっています。例えば以下の例を見てください。

### 原文

> The previous discussion on accuracy leads us to the related discussion on **consistency**. We do not need **strong consistency** for any of our use cases. When a user service updates a rate limit, this new rate limit need not immediately apply to new requests; a few seconds of inconsistency may be acceptable. **Eventual consistency** is also acceptable for viewing logged events such as which users were rate-limited or performing analytics on these logs. **Eventual** rather than **strong consistency** will allow a simpler and cheaper design.

### Claude 3.5の結果

> 精度についての前述の議論は、関連する**一貫性**の議論につながります。どのユースケースにも**強い一貫性**は必要ありません。ユーザーサービスがレートリミットを更新する場合、この新しいレートリミットが新しいリクエストに即座に適用される必要はありません。数秒間の不一致は許容される可能性があります。どのユーザーがレートリミットされたかなどのログイベントの表示や、これらのログの分析についても、**最終的な一貫性**で十分です。**強い一貫性**ではなく**最終的な一貫性**を使用することで、より単純で安価な設計が可能になります。

### これらの結果をもとにした最終的な訳文

> 精度についての前述の議論は、関連する**整合性***の議論につながります。どのユースケースにも**強い整合性**は必要ありません。ユーザーサービスがレートリミットを更新する場合、この新しいレートリミットが新しいリクエストに即座に適用される必要はありません。数秒間の不一致は許容される可能性があります。どのユーザーがレートリミットされたかなどのログイベントの表示や、これらのログの分析についても、**結果整合性**で十分です。**強い整合性**ではなく**結果整合性**を使用することで、より単純で安価な設計が可能になります。

ここで例に出しているのは「Eventual consistency」という用語です。「consistency」は「一貫性」とも「整合性」とも訳される用語で、Claude 3.5はこれを一貫性と訳していますが、翻訳では全て整合性という言葉を使うことにしました。「Eventual consistency」は最終的な一貫性とClaude 3.5は訳していますが、「結果整合性」と変更しています。ちなみに、Wikipediaでは「consistency」は「[一貫性](https://ja.wikipedia.org/wiki/%E4%B8%80%E8%B2%AB%E6%80%A7_(%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9))」と訳されていますが、「eventual consistency」は「[結果整合性](https://ja.wikipedia.org/wiki/%E7%B5%90%E6%9E%9C%E6%95%B4%E5%90%88%E6%80%A7)」と訳されています。

また、これ以外にも「Aでもなく、Bでもない」とすべき訳文を、Claude 3.5は「Aでもあり、Bでもある」というような全く逆の意味に訳してしまっている箇所がありました。

## 生成AIと翻訳その3 ( Claude 3.7 と GPT o1 Pro )

さて、ここから先は、まさに今行なっている新しい書籍の翻訳の話なのですが、現在は、Claude 3.7 と GPT o1 Pro を使って翻訳を行なっています。

